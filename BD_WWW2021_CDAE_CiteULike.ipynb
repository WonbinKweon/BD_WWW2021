{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.utils.data\n",
    "from torch.backends import cudnn\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import bottleneck as bn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5219\n",
      "25187\n",
      "130799\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "inter = 5\n",
    "train = torch.load('data/cul/train_' + str(inter) + '.pt')\n",
    "val = torch.load('data/cul/val_' + str(inter) + '.pt')\n",
    "test = torch.load('data/cul/test_' + str(inter) + '.pt')\n",
    "\n",
    "train_matrix = torch.load('data/cul/train_matrix_' + str(inter) + '.pt')\n",
    "train_nei = np.load('data/cul/train_nei_' + str(inter) + '.npy').item()\n",
    "\n",
    "train_matrix_input = train_matrix.clone().type(torch.FloatTensor)\n",
    "for idx, (u,i) in enumerate(val):\n",
    "    train_matrix_input[u][val[idx][1]] = 0\n",
    "    train_matrix_input[u][test[idx][1]] = 0\n",
    "\n",
    "num_users = train_matrix.size()[0]\n",
    "num_items = train_matrix.size()[1]\n",
    "\n",
    "print(num_users)\n",
    "print(num_items)\n",
    "print(train.size()[0]+val.size()[0]*2)\n",
    "\n",
    "# for neg_sample\n",
    "matrix = train_matrix.numpy()\n",
    "neg_max = num_items - min(np.sum(matrix, axis = 1))\n",
    "neg_count = neg_max - np.sum(matrix, axis = 1)\n",
    "\n",
    "i, j = np.where(matrix == 0)\n",
    "user = 0\n",
    "count = 0\n",
    "negs = []\n",
    "for index, idx in enumerate(i):\n",
    "    if user < idx:\n",
    "        user = idx\n",
    "        neg = j[count:index].tolist()\n",
    "        neg += [-1]*(int(neg_max)-len(neg))\n",
    "        negs.append(neg)\n",
    "        count = index \n",
    "neg = j[count:].tolist()\n",
    "neg += [-1]*(int(neg_max)-len(neg))        \n",
    "negs.append(neg)\n",
    "negs_np = np.array(negs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "class traindset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, idxs):\n",
    "        self.data = data\n",
    "        self.idxs = idxs\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.idxs[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return np.shape(self.data)[0]\n",
    "\n",
    "train_dset = traindset(train_matrix_input, torch.arange(num_users).type(torch.LongTensor))\n",
    "val_dset = traindset(val, torch.arange(num_users))\n",
    "test_dset = traindset(test, torch.arange(num_users))\n",
    "\n",
    "def HR(k, eval_sort):\n",
    "    eval_sort = eval_sort.cpu().numpy()\n",
    "    _, idy = np.where(eval_sort == 0)\n",
    "    \n",
    "    return len(np.where(idy < k)[0]) / len(eval_sort)\n",
    "\n",
    "def NDCG(k, eval_sort):\n",
    "    eval_sort = eval_sort.cpu().numpy()\n",
    "    _, idy = np.where(eval_sort == 0) # N\n",
    "    rank = idy[np.where(idy < k)[0]]\n",
    "    \n",
    "    return np.sum(1 / np.log2(rank+2)) / len(eval_sort)\n",
    "\n",
    "def get_KD_instances(u, idx):\n",
    "    weight_KD_T = torch.zeros_like(u)\n",
    "    weight_KD_S = torch.zeros_like(u)\n",
    "    for i in range(len(idx)):\n",
    "        neg_idx_T = torch.multinomial(weights_T[idx[i]], int(torch.sum(u[i])*num_neg), replacement=True)\n",
    "        neg_idx_S = torch.multinomial(weights_S[idx[i]], int(torch.sum(u[i])*num_neg), replacement=True)\n",
    "        negs_T = rank_matrix_T[idx[i]][neg_idx_T]\n",
    "        negs_S = rank_matrix_S[idx[i]][neg_idx_S]\n",
    "        weight_KD_T[i, negs_T] = 1\n",
    "        weight_KD_S[i, negs_S] = 1\n",
    "\n",
    "    return weight_KD_T, weight_KD_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base model - CDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDAE(nn.Module):\n",
    "    def __init__(self, hid_dim, matrix, temp):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.num_users = matrix.size()[0]\n",
    "        self.num_items = matrix.size()[1]\n",
    "        self.hid_dim = hid_dim\n",
    "        self.matrix = matrix.cuda(gpu)\n",
    "        self.temp = temp\n",
    "\n",
    "        self.u_emb = nn.Embedding(self.num_users, hid_dim)\n",
    "        \n",
    "        self.E = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(num_items, hid_dim)\n",
    "        )\n",
    "\n",
    "        self.D = nn.Sequential(\n",
    "            nn.Linear(hid_dim, num_items),\n",
    "        ) \n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, u, idx):\n",
    "        wyu = self.E(u)\n",
    "        vu = self.u_emb(idx)\n",
    "        \n",
    "        zu = wyu + vu\n",
    "        zu = self.sig(zu)\n",
    "        \n",
    "        hu = self.D(zu)\n",
    "        u_recon = self.sig(hu)\n",
    "        u_recon_tmp = self.sig(hu / self.temp)\n",
    "\n",
    "        # negative sampling\n",
    "        weight_CF = u.clone().view(-1, num_items)\n",
    "        for i in range(len(idx)):\n",
    "            neg_idx = np.random.randint(0, neg_count[idx[i]], size=(1, int(torch.sum(u[i])*num_neg)))\n",
    "            neg_items = np.array(negs_np[idx[i], neg_idx])\n",
    "            weight_CF[i, neg_items] = 1\n",
    "\n",
    "        return u_recon, u_recon_tmp, weight_CF\n",
    "\n",
    "    def evaluation(self, pairs, idx):\n",
    "        # indices\n",
    "        users = pairs[:, 0]\n",
    "        pos_items = pairs[:, 1].cpu().numpy().reshape((len(users), 1))\n",
    "        neg_items = np.zeros((len(users), 99))\n",
    "        for i in range(len(users)):\n",
    "            neg_idx = np.random.randint(0, neg_count[users[i]], size=(1, 99))\n",
    "            neg_items[i] = np.array(negs_np[users[i], neg_idx])\n",
    "        eval_items = torch.LongTensor(np.concatenate((pos_items, neg_items), axis=1)).cuda(gpu)\n",
    "        \n",
    "        us = self.matrix[users]\n",
    "        us_recon, _, _ = self.forward(us, idx)\n",
    "        eval_sort_sum = torch.zeros_like(eval_items).cuda(gpu)\n",
    "        for i in range(len(users)):\n",
    "            u_recon = us_recon[i]\n",
    "            u_recon_eval = u_recon[eval_items[i]]\n",
    "            eval_sort = torch.argsort(u_recon_eval, descending=True)\n",
    "            eval_sort_sum[i] = eval_sort\n",
    "\n",
    "        return HR(5, eval_sort_sum), HR(10, eval_sort_sum), HR(20, eval_sort_sum), NDCG(5, eval_sort_sum), NDCG(10, eval_sort_sum), NDCG(20, eval_sort_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "T_size = 50\n",
    "S_size = 5\n",
    "T = CDAE(T_size, train_matrix_input, 1)\n",
    "S = CDAE(S_size, train_matrix_input, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 100, loss = 1113.163, time = 1.9527\n",
      "epoch = 200, loss = 836.975, time = 1.9579\n",
      "epoch = 300, loss = 702.046, time = 1.9527\n",
      "epoch = 400, loss = 623.107, time = 1.9413\n",
      "epoch = 500, loss = 571.847, time = 1.9532\n"
     ]
    }
   ],
   "source": [
    "# Teacher\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.001\n",
    "wd = 0.001\n",
    "num_neg = 5\n",
    "epochs = 500\n",
    "verbose = 100\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "optimizer = optim.Adam(T.parameters(), lr = lr, weight_decay = wd)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "if use_cuda:\n",
    "    T = T.cuda(gpu)\n",
    "    criterion = criterion.cuda(gpu)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    T.train()\n",
    "    loss_train = np.zeros(1)\n",
    "    t0 = time.time()\n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        us_recon, _, weight = T(us, idxs)\n",
    "\n",
    "        loss = torch.sum(criterion(us_recon, us) * weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train[0] += loss.cpu().tolist() \n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        print('epoch = {}, loss = {:.3f}, time = {:.4f}'.format(epoch, loss_train[0], time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 100, loss = 5680.112, time = 1.8433\n",
      "epoch = 200, loss = 4755.955, time = 1.9039\n",
      "epoch = 300, loss = 4294.408, time = 1.9284\n",
      "epoch = 400, loss = 4008.256, time = 1.9149\n",
      "epoch = 500, loss = 3835.516, time = 1.9264\n",
      "epoch = 600, loss = 3704.248, time = 2.2687\n",
      "epoch = 700, loss = 3606.717, time = 2.2265\n",
      "epoch = 800, loss = 3519.600, time = 2.1803\n",
      "epoch = 900, loss = 3477.575, time = 2.1609\n",
      "epoch = 1000, loss = 3422.638, time = 2.1282\n"
     ]
    }
   ],
   "source": [
    "# Student\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.002\n",
    "wd = 0.001\n",
    "num_neg = 5\n",
    "epochs = 1000\n",
    "verbose = 100\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "optimizer = optim.Adam(S.parameters(), lr = lr, weight_decay = wd)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "if use_cuda:\n",
    "    S = S.cuda(gpu)\n",
    "    criterion = criterion.cuda(gpu)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    S.train()\n",
    "    loss_train = np.zeros(1)\n",
    "    t0 = time.time()\n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        us_recon, _, weight = S(us, idxs)\n",
    "\n",
    "        loss = torch.sum(criterion(us_recon, us) * weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train[0] += loss.cpu().tolist() \n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        print('epoch = {}, loss = {:.3f}, time = {:.4f}'.format(epoch, loss_train[0], time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2000, loss = 6627.438+8257.204= 0.000, time = 22.9211\n",
      "0.1926, 0.2761, 0.3623, 0.0523, 0.0658, 0.0779\n",
      "0.1004, 0.1470, 0.2190, 0.0287, 0.0362, 0.0463\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.002\n",
    "lamb_T = 0.5\n",
    "lamb_S = 0.5\n",
    "\n",
    "temp_T = 2\n",
    "temp_S = 2\n",
    "\n",
    "weight_func = 'tanhexp'\n",
    "eps = 1e-4\n",
    "eps_tanh = 1e-4\n",
    "num_neg = 5\n",
    "update = 10\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "# loss\n",
    "optimizer_T = optim.Adam(T.parameters(), lr = lr, weight_decay=0)\n",
    "optimizer_S = optim.Adam(S.parameters(), lr = lr, weight_decay=0)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "# cuda\n",
    "T = T.cuda(gpu)\n",
    "S = S.cuda(gpu)\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    loss_train = np.zeros(3)\n",
    "    t0 = time.time()\n",
    "\n",
    "    # update rank matrix\n",
    "    if (epoch % update == 0):\n",
    "        with torch.no_grad():\n",
    "            T.eval()\n",
    "            S.eval()\n",
    "            T.temp = 10\n",
    "            S.temp = 10\n",
    "            rank_matrix_T = torch.zeros_like(train_matrix_input).type(torch.LongTensor)\n",
    "            rank_matrix_S = torch.zeros_like(train_matrix_input).type(torch.LongTensor)\n",
    "            mask_matrix = 1-train_matrix_input.cuda(gpu).float()\n",
    "\n",
    "            for u in range(num_users):\n",
    "                us = train_matrix_input[u].cuda(gpu)\n",
    "                idx = torch.LongTensor([u]).cuda(gpu)\n",
    "                _, us_recon_tmp_T, _ = T(us, idx)\n",
    "                _, us_recon_tmp_S, _ = S(us, idx)\n",
    "                us_mask_T = us_recon_tmp_T * mask_matrix[u]\n",
    "                us_mask_S = us_recon_tmp_S * mask_matrix[u]\n",
    "                rank_list_T = torch.argsort(us_mask_T)\n",
    "                rank_list_S = torch.argsort(us_mask_S)\n",
    "                rank_matrix_T[u] = rank_list_T\n",
    "                rank_matrix_S[u] = rank_list_S\n",
    "\n",
    "            ranklist_T = torch.zeros_like(rank_matrix_T)\n",
    "            for i in range(len(ranklist_T)):\n",
    "                row = rank_matrix_T[i]\n",
    "                ranklist_T[i][row] = torch.LongTensor(np.arange(len(row))) + 1\n",
    "\n",
    "            ranklist_S = torch.zeros_like(rank_matrix_S)\n",
    "            for i in range(len(ranklist_S)):\n",
    "                row = rank_matrix_S[i]\n",
    "                ranklist_S[i][row] = torch.LongTensor(np.arange(len(row))) + 1\n",
    "\n",
    "            rank_dif_TS = ranklist_T - ranklist_S # 작으면 T가 더 높게한거, 크면 S가 더 높게한거\n",
    "            rank_dif_ST = ranklist_S - ranklist_T # 작으면 T가 더 높게한거, 크면 S가 더 높게한거\n",
    "            if weight_func == 'linear':\n",
    "                weights_T = torch.max(-rank_dif_TS.type(torch.FloatTensor) * eps, torch.zeros_like(rank_dif_TS).type(torch.FloatTensor)).cuda(gpu)\n",
    "                weights_S = torch.max(-rank_dif_ST.type(torch.FloatTensor) * eps, torch.zeros_like(rank_dif_TS).type(torch.FloatTensor)).cuda(gpu) \n",
    "            elif weight_func == 'exp':\n",
    "                weights_T = torch.exp(-rank_dif_TS.type(torch.FloatTensor) * eps).cuda(gpu)\n",
    "                weights_S = torch.exp(-rank_dif_ST.type(torch.FloatTensor) * eps).cuda(gpu)                            \n",
    "            elif weight_func == 'tanh':\n",
    "                weights_T = torch.tanh(torch.max(-rank_dif_TS.type(torch.FloatTensor) * eps_tanh, torch.zeros_like(rank_dif_TS).type(torch.FloatTensor))).cuda(gpu)\n",
    "                weights_S = torch.tanh(torch.max(-rank_dif_ST.type(torch.FloatTensor) * eps_tanh, torch.zeros_like(rank_dif_TS).type(torch.FloatTensor))).cuda(gpu)\n",
    "            elif weight_func == 'exptanh':\n",
    "                weights_T = torch.exp(-rank_dif_TS.type(torch.FloatTensor) * eps).cuda(gpu)\n",
    "                weights_S = torch.tanh(torch.max(-rank_dif_ST.type(torch.FloatTensor) * eps_tanh, torch.zeros_like(rank_dif_TS).type(torch.FloatTensor))).cuda(gpu)\n",
    "            elif weight_func == 'tanhexp':\n",
    "                weights_T = torch.tanh(torch.max(-rank_dif_TS.type(torch.FloatTensor) * eps_tanh, torch.zeros_like(rank_dif_TS).type(torch.FloatTensor))).cuda(gpu)\n",
    "                weights_S = torch.exp(-rank_dif_ST.type(torch.FloatTensor) * eps).cuda(gpu)\n",
    "            else:\n",
    "                print(\"plz select proper weight function!\") \n",
    "\n",
    "    T.train()\n",
    "    S.train()\n",
    "    T.temp = temp_T\n",
    "    S.temp = temp_S                                            \n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        ### train\n",
    "        optimizer_T.zero_grad()\n",
    "        optimizer_S.zero_grad()\n",
    "        uT, uT_tmp, weightT_CF = T(us, idxs)\n",
    "        uS, uS_tmp, weightS_CF = S(us, idxs)\n",
    "        weightT_KD, weightS_KD = get_KD_instances(us, idxs)\n",
    "\n",
    "        ### For T\n",
    "        pseudo_label = uS_tmp.detach()\n",
    "        loss_T_WS = torch.sum(criterion(uT, pseudo_label) * weightT_KD)\n",
    "        loss_T_CF = torch.sum(criterion(uT, us) * weightT_CF)\n",
    "        loss_T = loss_T_CF + loss_T_WS * lamb_T\n",
    "        loss_T.backward()\n",
    "        optimizer_T.step()\n",
    "\n",
    "        ### For S\n",
    "        pseudo_label = uT_tmp.detach()\n",
    "        loss_S_WS = torch.sum(criterion(uS, pseudo_label) * weightS_KD)\n",
    "        loss_S_CF = torch.sum(criterion(uS, us) * weightS_CF)\n",
    "        loss_S = loss_S_CF + loss_S_WS * lamb_S\n",
    "        loss_S.backward()\n",
    "        optimizer_S.step()\n",
    "\n",
    "        #loss_train[0] += loss.cpu().tolist() \n",
    "        loss_train[1] += loss_T.cpu().tolist() \n",
    "        loss_train[2] += loss_S.cpu().tolist()\n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "print('epoch = {}, loss = {:.3f}+{:.3f}= {:.3f}, time = {:.4f}'.format(epoch, loss_train[1], loss_train[2], loss_train[0], time.time()-t0))\n",
    "## full val\n",
    "rank_T = []\n",
    "for row in test:\n",
    "    row = row.numpy()\n",
    "    rank_T.append(num_items - np.where(rank_matrix_T[row[0]] == row[1])[0][0])\n",
    "rank_T = np.array(rank_T)\n",
    "ndcg = 1 / np.log2(rank_T + 2)\n",
    "\n",
    "print(\"{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format((rank_T < 50).mean(), (rank_T < 100).mean(), (rank_T < 200).mean(), (ndcg * (rank_T < 50)).mean(), (ndcg * (rank_T < 100)).mean(), (ndcg * (rank_T < 200)).mean()))\n",
    "\n",
    "rank_S = []\n",
    "for row in test:\n",
    "    row = row.numpy()\n",
    "    rank_S.append(num_items - np.where(rank_matrix_S[row[0]] == row[1])[0][0])\n",
    "rank_S = np.array(rank_S)\n",
    "ndcg = 1 / np.log2(rank_S + 2)\n",
    "\n",
    "print(\"{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format((rank_S < 50).mean(), (rank_S < 100).mean(), (rank_S < 200).mean(), (ndcg * (rank_S < 50)).mean(), (ndcg * (rank_S < 100)).mean(), (ndcg * (rank_S < 200)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbaseconda7d83067cfd6040cb9b83bec122768017"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
