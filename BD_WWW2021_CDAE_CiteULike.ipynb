{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.utils.data\n",
    "from torch.backends import cudnn\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import bottleneck as bn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5219\n",
      "25187\n",
      "130799\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "inter = 5\n",
    "train = torch.load('data/cul/train_' + str(inter) + '.pt')\n",
    "val = torch.load('data/cul/val_' + str(inter) + '.pt')\n",
    "test = torch.load('data/cul/test_' + str(inter) + '.pt')\n",
    "\n",
    "train_matrix = torch.load('data/cul/train_matrix_' + str(inter) + '.pt')\n",
    "train_nei = np.load('data/cul/train_nei_' + str(inter) + '.npy').item()\n",
    "\n",
    "train_matrix_input = train_matrix.clone().type(torch.FloatTensor)\n",
    "for idx, (u,i) in enumerate(val):\n",
    "    train_matrix_input[u][val[idx][1]] = 0\n",
    "    train_matrix_input[u][test[idx][1]] = 0\n",
    "\n",
    "num_users = train_matrix.size()[0]\n",
    "num_items = train_matrix.size()[1]\n",
    "\n",
    "print(num_users)\n",
    "print(num_items)\n",
    "print(train.size()[0]+val.size()[0]*2)\n",
    "\n",
    "# for neg_sample\n",
    "matrix = train_matrix.numpy()\n",
    "neg_max = num_items - min(np.sum(matrix, axis = 1))\n",
    "neg_count = neg_max - np.sum(matrix, axis = 1)\n",
    "\n",
    "i, j = np.where(matrix == 0)\n",
    "user = 0\n",
    "count = 0\n",
    "negs = []\n",
    "for index, idx in enumerate(i):\n",
    "    if user < idx:\n",
    "        user = idx\n",
    "        neg = j[count:index].tolist()\n",
    "        neg += [-1]*(int(neg_max)-len(neg))\n",
    "        negs.append(neg)\n",
    "        count = index \n",
    "neg = j[count:].tolist()\n",
    "neg += [-1]*(int(neg_max)-len(neg))        \n",
    "negs.append(neg)\n",
    "negs_np = np.array(negs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "class traindset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, idxs):\n",
    "        self.data = data\n",
    "        self.idxs = idxs\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.idxs[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return np.shape(self.data)[0]\n",
    "\n",
    "train_dset = traindset(train_matrix_input, torch.arange(num_users).type(torch.LongTensor))\n",
    "val_dset = traindset(val, torch.arange(num_users))\n",
    "test_dset = traindset(test, torch.arange(num_users))\n",
    "\n",
    "def HR(k, eval_sort):\n",
    "    eval_sort = eval_sort.cpu().numpy()\n",
    "    _, idy = np.where(eval_sort == 0)\n",
    "    \n",
    "    return len(np.where(idy < k)[0]) / len(eval_sort)\n",
    "\n",
    "def NDCG(k, eval_sort):\n",
    "    eval_sort = eval_sort.cpu().numpy()\n",
    "    _, idy = np.where(eval_sort == 0) # N\n",
    "    rank = idy[np.where(idy < k)[0]]\n",
    "    \n",
    "    return np.sum(1 / np.log2(rank+2)) / len(eval_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base model - CDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDAE(nn.Module):\n",
    "    def __init__(self, hid_dim, matrix, temp):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.num_users = matrix.size()[0]\n",
    "        self.num_items = matrix.size()[1]\n",
    "        self.hid_dim = hid_dim\n",
    "        self.matrix = matrix.cuda(gpu)\n",
    "        self.temp = temp\n",
    "\n",
    "        self.u_emb = nn.Embedding(self.num_users, hid_dim)\n",
    "        \n",
    "        self.E = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(num_items, hid_dim)\n",
    "        )\n",
    "\n",
    "        self.D = nn.Sequential(\n",
    "            nn.Linear(hid_dim, num_items),\n",
    "        ) \n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, u, idx):\n",
    "        wyu = self.E(u)\n",
    "        vu = self.u_emb(idx)\n",
    "        \n",
    "        zu = wyu + vu\n",
    "        zu = self.sig(zu)\n",
    "        \n",
    "        hu = self.D(zu)\n",
    "        u_recon = self.sig(hu)\n",
    "        u_recon_tmp = self.sig(hu / self.temp)\n",
    "\n",
    "        # negative sampling\n",
    "        weight_CF = u.clone().view(-1, num_items)\n",
    "        for i in range(len(idx)):\n",
    "            neg_idx = np.random.randint(0, neg_count[idx[i]], size=(1, int(torch.sum(u[i])*num_neg)))\n",
    "            neg_items = np.array(negs_np[idx[i], neg_idx])\n",
    "            weight_CF[i, neg_items] = 1\n",
    "\n",
    "        return u_recon, u_recon_tmp, weight_CF\n",
    "    \n",
    "    # not used\n",
    "    def evaluation(self, pairs, idx):\n",
    "        # indices\n",
    "        users = pairs[:, 0]\n",
    "        pos_items = pairs[:, 1].cpu().numpy().reshape((len(users), 1))\n",
    "        neg_items = np.zeros((len(users), 99))\n",
    "        for i in range(len(users)):\n",
    "            neg_idx = np.random.randint(0, neg_count[users[i]], size=(1, 99))\n",
    "            neg_items[i] = np.array(negs_np[users[i], neg_idx])\n",
    "        eval_items = torch.LongTensor(np.concatenate((pos_items, neg_items), axis=1)).cuda(gpu)\n",
    "        \n",
    "        us = self.matrix[users]\n",
    "        us_recon, _, _ = self.forward(us, idx)\n",
    "        eval_sort_sum = torch.zeros_like(eval_items).cuda(gpu)\n",
    "        for i in range(len(users)):\n",
    "            u_recon = us_recon[i]\n",
    "            u_recon_eval = u_recon[eval_items[i]]\n",
    "            eval_sort = torch.argsort(u_recon_eval, descending=True)\n",
    "            eval_sort_sum[i] = eval_sort\n",
    "\n",
    "        return HR(5, eval_sort_sum), HR(10, eval_sort_sum), HR(20, eval_sort_sum), NDCG(5, eval_sort_sum), NDCG(10, eval_sort_sum), NDCG(20, eval_sort_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "T_size = 50\n",
    "S_size = 5\n",
    "T = CDAE(T_size, train_matrix_input, 1)\n",
    "S = CDAE(S_size, train_matrix_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.002\n",
    "wd = 0.001\n",
    "num_neg = 5\n",
    "epochs = 1000\n",
    "verbose = 100\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "optimizer = optim.Adam(T.parameters(), lr = lr, weight_decay = wd)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "if use_cuda:\n",
    "    T = T.cuda(gpu)\n",
    "    criterion = criterion.cuda(gpu)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    T.train()\n",
    "    loss_train = np.zeros(1)\n",
    "    t0 = time.time()\n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        us_recon, _, weight = T(us, idxs)\n",
    "\n",
    "        loss = torch.sum(criterion(us_recon, us) * weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train[0] += loss.cpu().tolist() \n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        print('epoch = {}, loss = {:.3f}, time = {:.4f}'.format(epoch, loss_train[0], time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.002\n",
    "wd = 0.001\n",
    "num_neg = 5\n",
    "epochs = 1000\n",
    "verbose = 100\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "optimizer = optim.Adam(S.parameters(), lr = lr, weight_decay = wd)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "if use_cuda:\n",
    "    S = S.cuda(gpu)\n",
    "    criterion = criterion.cuda(gpu)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    S.train()\n",
    "    loss_train = np.zeros(1)\n",
    "    t0 = time.time()\n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        us_recon, _, weight = S(us, idxs)\n",
    "\n",
    "        loss = torch.sum(criterion(us_recon, us) * weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train[0] += loss.cpu().tolist() \n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        print('epoch = {}, loss = {:.3f}, time = {:.4f}'.format(epoch, loss_train[0], time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "T = torch.load('model/CDAE/CDAE' + str(50)+'_cul_'  + str(inter) + '.pt', map_location = 'cuda:'+str(gpu))\n",
    "S = torch.load('model/CDAE/CDAE' + str(5)+'_cul_'  + str(inter) + '.pt', map_location = 'cuda:'+str(gpu))\n",
    "\n",
    "# sampling function\n",
    "def get_KD_instances(u, idx):\n",
    "    weight_KD_T = torch.zeros_like(u)\n",
    "    weight_KD_S = torch.zeros_like(u)\n",
    "    for i in range(len(idx)):\n",
    "        neg_idx_T = torch.multinomial(weights_T[idx[i]], int(torch.sum(u[i])*num_neg), replacement=True)\n",
    "        neg_idx_S = torch.multinomial(weights_S[idx[i]], int(torch.sum(u[i])*num_neg), replacement=True)\n",
    "        weight_KD_T[i, neg_idx_T] = 1\n",
    "        weight_KD_S[i, neg_idx_S] = 1\n",
    "\n",
    "    return weight_KD_T, weight_KD_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, loss = 4239.797+5040.660= 0.000, time = 37.1398\n",
      "0.1820, 0.2393, 0.3112, 0.0502, 0.0594, 0.0695\n",
      "0.0788, 0.1205, 0.1769, 0.0234, 0.0301, 0.0379\n",
      "epoch = 100, loss = 3572.586+5617.319= 0.000, time = 34.5602\n",
      "0.1878, 0.2514, 0.3250, 0.0531, 0.0634, 0.0737\n",
      "0.0879, 0.1337, 0.2020, 0.0266, 0.0340, 0.0435\n",
      "epoch = 200, loss = 3690.914+5703.032= 0.000, time = 33.5163\n",
      "0.1884, 0.2550, 0.3271, 0.0534, 0.0642, 0.0742\n",
      "0.0908, 0.1370, 0.2067, 0.0271, 0.0346, 0.0443\n",
      "epoch = 300, loss = 3766.166+5746.945= 0.000, time = 35.2796\n",
      "0.1918, 0.2522, 0.3246, 0.0543, 0.0641, 0.0741\n",
      "0.0948, 0.1397, 0.2121, 0.0284, 0.0357, 0.0458\n",
      "epoch = 400, loss = 3798.511+5747.319= 0.000, time = 35.0651\n",
      "0.1889, 0.2560, 0.3234, 0.0550, 0.0659, 0.0753\n",
      "0.0948, 0.1420, 0.2163, 0.0287, 0.0364, 0.0467\n",
      "epoch = 500, loss = 3819.729+5748.826= 0.000, time = 36.3051\n",
      "0.1941, 0.2568, 0.3298, 0.0558, 0.0659, 0.0761\n",
      "0.0989, 0.1468, 0.2198, 0.0293, 0.0370, 0.0472\n",
      "epoch = 600, loss = 3814.322+5727.398= 0.000, time = 35.5852\n",
      "0.1928, 0.2535, 0.3305, 0.0558, 0.0657, 0.0764\n",
      "0.1016, 0.1483, 0.2207, 0.0301, 0.0375, 0.0476\n",
      "epoch = 700, loss = 3832.373+5710.709= 0.000, time = 35.3236\n",
      "0.1937, 0.2604, 0.3305, 0.0562, 0.0670, 0.0768\n",
      "0.1006, 0.1473, 0.2248, 0.0299, 0.0375, 0.0483\n",
      "epoch = 800, loss = 3811.282+5703.450= 0.000, time = 23.1678\n",
      "0.1970, 0.2583, 0.3305, 0.0575, 0.0675, 0.0776\n",
      "0.1031, 0.1508, 0.2251, 0.0307, 0.0384, 0.0487\n",
      "epoch = 900, loss = 3803.416+5682.022= 0.000, time = 23.4228\n",
      "0.2014, 0.2558, 0.3307, 0.0584, 0.0673, 0.0778\n",
      "0.1039, 0.1495, 0.2276, 0.0310, 0.0384, 0.0493\n",
      "epoch = 1000, loss = 3819.933+5668.398= 0.000, time = 22.4071\n",
      "0.2002, 0.2621, 0.3299, 0.0589, 0.0689, 0.0784\n",
      "0.1046, 0.1554, 0.2280, 0.0310, 0.0392, 0.0493\n",
      "epoch = 1100, loss = 3802.956+5638.848= 0.000, time = 23.0539\n",
      "0.2008, 0.2677, 0.3359, 0.0596, 0.0704, 0.0800\n",
      "0.1037, 0.1546, 0.2288, 0.0311, 0.0393, 0.0496\n",
      "epoch = 1200, loss = 3794.530+5636.265= 0.000, time = 22.9552\n",
      "0.1991, 0.2627, 0.3303, 0.0589, 0.0692, 0.0787\n",
      "0.1046, 0.1556, 0.2278, 0.0313, 0.0395, 0.0496\n",
      "epoch = 1300, loss = 3779.065+5619.730= 0.000, time = 22.7123\n",
      "0.2031, 0.2621, 0.3321, 0.0602, 0.0698, 0.0796\n",
      "0.1054, 0.1548, 0.2311, 0.0318, 0.0398, 0.0504\n",
      "epoch = 1400, loss = 3761.446+5611.891= 0.000, time = 22.7986\n",
      "0.1991, 0.2635, 0.3321, 0.0594, 0.0699, 0.0795\n",
      "0.1052, 0.1539, 0.2265, 0.0311, 0.0390, 0.0491\n",
      "epoch = 1500, loss = 3745.455+5597.130= 0.000, time = 22.6102\n",
      "0.2018, 0.2637, 0.3395, 0.0597, 0.0697, 0.0803\n",
      "0.1067, 0.1560, 0.2288, 0.0320, 0.0399, 0.0501\n",
      "epoch = 1600, loss = 3746.156+5585.291= 0.000, time = 23.1714\n",
      "0.1989, 0.2646, 0.3378, 0.0588, 0.0695, 0.0797\n",
      "0.1031, 0.1565, 0.2334, 0.0311, 0.0397, 0.0504\n",
      "epoch = 1700, loss = 3735.041+5577.190= 0.000, time = 22.6866\n",
      "0.2025, 0.2667, 0.3326, 0.0607, 0.0711, 0.0803\n",
      "0.1058, 0.1562, 0.2305, 0.0322, 0.0403, 0.0507\n",
      "epoch = 1800, loss = 3734.324+5567.998= 0.000, time = 22.3322\n",
      "0.2006, 0.2598, 0.3345, 0.0598, 0.0695, 0.0800\n",
      "0.1067, 0.1573, 0.2343, 0.0321, 0.0402, 0.0510\n",
      "epoch = 1900, loss = 3726.554+5578.043= 0.000, time = 22.6250\n",
      "0.2014, 0.2623, 0.3376, 0.0599, 0.0698, 0.0803\n",
      "0.1067, 0.1552, 0.2332, 0.0323, 0.0402, 0.0510\n",
      "epoch = 2000, loss = 3721.853+5545.077= 0.000, time = 22.0313\n",
      "0.2031, 0.2615, 0.3365, 0.0601, 0.0696, 0.0800\n",
      "0.1063, 0.1573, 0.2366, 0.0320, 0.0402, 0.0513\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.002\n",
    "lamb_T = 0.5\n",
    "lamb_S = 0.5\n",
    "\n",
    "temp_T = 2\n",
    "temp_S = 2\n",
    "\n",
    "eps = 1e-4\n",
    "eps_tanh = 1e-4\n",
    "num_neg = 5\n",
    "update = 10\n",
    "\n",
    "epochs = 2000\n",
    "verbose = 100\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "# loss\n",
    "optimizer_T = optim.Adam(T.parameters(), lr = lr, weight_decay=0)\n",
    "optimizer_S = optim.Adam(S.parameters(), lr = lr, weight_decay=0)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "# cuda\n",
    "T = T.cuda(gpu)\n",
    "S = S.cuda(gpu)\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    loss_train = np.zeros(3)\n",
    "    t0 = time.time()\n",
    "\n",
    "    # update rank matrix\n",
    "    if (epoch % update == 0):\n",
    "        with torch.no_grad():\n",
    "            T.eval()\n",
    "            S.eval()\n",
    "            T.temp = 10\n",
    "            S.temp = 10\n",
    "            rank_matrix_T = torch.zeros_like(train_matrix_input).type(torch.LongTensor)\n",
    "            rank_matrix_S = torch.zeros_like(train_matrix_input).type(torch.LongTensor)\n",
    "            mask_matrix = 1-train_matrix_input.cuda(gpu).float()\n",
    "\n",
    "            for u in range(num_users):\n",
    "                us = train_matrix_input[u].cuda(gpu)\n",
    "                idx = torch.LongTensor([u]).cuda(gpu)\n",
    "                _, us_recon_tmp_T, _ = T(us, idx)\n",
    "                _, us_recon_tmp_S, _ = S(us, idx)\n",
    "                us_mask_T = us_recon_tmp_T * mask_matrix[u]\n",
    "                us_mask_S = us_recon_tmp_S * mask_matrix[u]\n",
    "                rank_list_T = torch.argsort(us_mask_T)\n",
    "                rank_list_S = torch.argsort(us_mask_S)\n",
    "                rank_matrix_T[u] = rank_list_T\n",
    "                rank_matrix_S[u] = rank_list_S\n",
    "\n",
    "            ranklist_T = torch.zeros_like(rank_matrix_T)\n",
    "            for i in range(len(ranklist_T)):\n",
    "                row = rank_matrix_T[i]\n",
    "                ranklist_T[i][row] = torch.LongTensor(np.arange(len(row))) + 1\n",
    "\n",
    "            ranklist_S = torch.zeros_like(rank_matrix_S)\n",
    "            for i in range(len(ranklist_S)):\n",
    "                row = rank_matrix_S[i]\n",
    "                ranklist_S[i][row] = torch.LongTensor(np.arange(len(row))) + 1\n",
    "\n",
    "            rank_dif_T = ranklist_T - ranklist_S # T가 못한거\n",
    "            rank_dif_S = ranklist_S - ranklist_T # S가 못한거\n",
    "\n",
    "            weights_T = torch.exp(rank_dif_T.type(torch.FloatTensor) * eps).cuda(gpu)\n",
    "            weights_S = torch.tanh(torch.max(rank_dif_S.type(torch.FloatTensor) * eps_tanh, torch.zeros_like(rank_dif_T).type(torch.FloatTensor))).cuda(gpu) \n",
    "\n",
    "    T.train()\n",
    "    S.train()\n",
    "    T.temp = temp_T\n",
    "    S.temp = temp_S                                            \n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        ### train\n",
    "        optimizer_T.zero_grad()\n",
    "        optimizer_S.zero_grad()\n",
    "        uT, uT_tmp, weightT_CF = T(us, idxs)\n",
    "        uS, uS_tmp, weightS_CF = S(us, idxs)\n",
    "        weightT_KD, weightS_KD = get_KD_instances(us, idxs)\n",
    "\n",
    "        ### For T\n",
    "        pseudo_label = uS_tmp.detach()\n",
    "        loss_T_WS = torch.sum(criterion(uT, pseudo_label) * weightT_KD)\n",
    "        loss_T_CF = torch.sum(criterion(uT, us) * weightT_CF)\n",
    "        loss_T = loss_T_CF + loss_T_WS * lamb_T\n",
    "        loss_T.backward()\n",
    "        optimizer_T.step()\n",
    "\n",
    "        ### For S\n",
    "        pseudo_label = uT_tmp.detach()\n",
    "        loss_S_WS = torch.sum(criterion(uS, pseudo_label) * weightS_KD)\n",
    "        loss_S_CF = torch.sum(criterion(uS, us) * weightS_CF)\n",
    "        loss_S = loss_S_CF + loss_S_WS * lamb_S\n",
    "        loss_S.backward()\n",
    "        optimizer_S.step()\n",
    "\n",
    "        #loss_train[0] += loss.cpu().tolist() \n",
    "        loss_train[1] += loss_T.cpu().tolist() \n",
    "        loss_train[2] += loss_S.cpu().tolist()\n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        print('epoch = {}, loss = {:.3f}+{:.3f}= {:.3f}, time = {:.4f}'.format(epoch, loss_train[1], loss_train[2], loss_train[0], time.time()-t0))\n",
    "        ## full val\n",
    "        rank_T = []\n",
    "        for row in test:\n",
    "            row = row.numpy()\n",
    "            rank_T.append(num_items - np.where(rank_matrix_T[row[0]] == row[1])[0][0])\n",
    "        rank_T = np.array(rank_T)\n",
    "        ndcg = 1 / np.log2(rank_T + 2)\n",
    "\n",
    "        print(\"{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format((rank_T < 50).mean(), (rank_T < 100).mean(), (rank_T < 200).mean(), (ndcg * (rank_T < 50)).mean(), (ndcg * (rank_T < 100)).mean(), (ndcg * (rank_T < 200)).mean()))\n",
    "\n",
    "        rank_S = []\n",
    "        for row in test:\n",
    "            row = row.numpy()\n",
    "            rank_S.append(num_items - np.where(rank_matrix_S[row[0]] == row[1])[0][0])\n",
    "        rank_S = np.array(rank_S)\n",
    "        ndcg = 1 / np.log2(rank_S + 2)\n",
    "\n",
    "        print(\"{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format((rank_S < 50).mean(), (rank_S < 100).mean(), (rank_S < 200).mean(), (ndcg * (rank_S < 50)).mean(), (ndcg * (rank_S < 100)).mean(), (ndcg * (rank_S < 200)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbaseconda7d83067cfd6040cb9b83bec122768017"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
