{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import torch.utils.data\n",
    "from torch.backends import cudnn\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import bottleneck as bn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5219\n",
      "25187\n",
      "130799\n"
     ]
    }
   ],
   "source": [
    "gpu = 0\n",
    "inter = 5\n",
    "train = torch.load('data/cul/train_' + str(inter) + '.pt')\n",
    "val = torch.load('data/cul/val_' + str(inter) + '.pt')\n",
    "test = torch.load('data/cul/test_' + str(inter) + '.pt')\n",
    "\n",
    "train_matrix = torch.load('data/cul/train_matrix_' + str(inter) + '.pt')\n",
    "train_nei = np.load('data/cul/train_nei_' + str(inter) + '.npy').item()\n",
    "\n",
    "train_matrix_input = train_matrix.clone().type(torch.FloatTensor)\n",
    "for idx, (u,i) in enumerate(val):\n",
    "    train_matrix_input[u][val[idx][1]] = 0\n",
    "    train_matrix_input[u][test[idx][1]] = 0\n",
    "\n",
    "num_users = train_matrix.size()[0]\n",
    "num_items = train_matrix.size()[1]\n",
    "\n",
    "print(num_users)\n",
    "print(num_items)\n",
    "print(train.size()[0]+val.size()[0]*2)\n",
    "\n",
    "# for neg_sample\n",
    "matrix = train_matrix.numpy()\n",
    "neg_max = num_items - min(np.sum(matrix, axis = 1))\n",
    "neg_count = neg_max - np.sum(matrix, axis = 1)\n",
    "\n",
    "i, j = np.where(matrix == 0)\n",
    "user = 0\n",
    "count = 0\n",
    "negs = []\n",
    "for index, idx in enumerate(i):\n",
    "    if user < idx:\n",
    "        user = idx\n",
    "        neg = j[count:index].tolist()\n",
    "        neg += [-1]*(int(neg_max)-len(neg))\n",
    "        negs.append(neg)\n",
    "        count = index \n",
    "neg = j[count:].tolist()\n",
    "neg += [-1]*(int(neg_max)-len(neg))        \n",
    "negs.append(neg)\n",
    "negs_np = np.array(negs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "class traindset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, idxs):\n",
    "        self.data = data\n",
    "        self.idxs = idxs\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.idxs[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return np.shape(self.data)[0]\n",
    "\n",
    "train_dset = traindset(train_matrix_input, torch.arange(num_users).type(torch.LongTensor))\n",
    "val_dset = traindset(val, torch.arange(num_users))\n",
    "test_dset = traindset(test, torch.arange(num_users))\n",
    "\n",
    "def HR(k, eval_sort):\n",
    "    eval_sort = eval_sort.cpu().numpy()\n",
    "    _, idy = np.where(eval_sort == 0)\n",
    "    \n",
    "    return len(np.where(idy < k)[0]) / len(eval_sort)\n",
    "\n",
    "def NDCG(k, eval_sort):\n",
    "    eval_sort = eval_sort.cpu().numpy()\n",
    "    _, idy = np.where(eval_sort == 0) # N\n",
    "    rank = idy[np.where(idy < k)[0]]\n",
    "    \n",
    "    return np.sum(1 / np.log2(rank+2)) / len(eval_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base model - CDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDAE(nn.Module):\n",
    "    def __init__(self, hid_dim, matrix, temp):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.num_users = matrix.size()[0]\n",
    "        self.num_items = matrix.size()[1]\n",
    "        self.hid_dim = hid_dim\n",
    "        self.matrix = matrix.cuda(gpu)\n",
    "        self.temp = temp\n",
    "\n",
    "        self.u_emb = nn.Embedding(self.num_users, hid_dim)\n",
    "        \n",
    "        self.E = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(num_items, hid_dim)\n",
    "        )\n",
    "\n",
    "        self.D = nn.Sequential(\n",
    "            nn.Linear(hid_dim, num_items),\n",
    "        ) \n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, u, idx):\n",
    "        wyu = self.E(u)\n",
    "        vu = self.u_emb(idx)\n",
    "        \n",
    "        zu = wyu + vu\n",
    "        zu = self.sig(zu)\n",
    "        \n",
    "        hu = self.D(zu)\n",
    "        u_recon = self.sig(hu)\n",
    "        u_recon_tmp = self.sig(hu / self.temp)\n",
    "\n",
    "        # negative sampling\n",
    "        weight_CF = u.clone().view(-1, num_items)\n",
    "        for i in range(len(idx)):\n",
    "            neg_idx = np.random.randint(0, neg_count[idx[i]], size=(1, int(torch.sum(u[i])*num_neg)))\n",
    "            neg_items = np.array(negs_np[idx[i], neg_idx])\n",
    "            weight_CF[i, neg_items] = 1\n",
    "\n",
    "        return u_recon, u_recon_tmp, weight_CF\n",
    "    \n",
    "    # not used\n",
    "    def evaluation(self, pairs, idx):\n",
    "        # indices\n",
    "        users = pairs[:, 0]\n",
    "        pos_items = pairs[:, 1].cpu().numpy().reshape((len(users), 1))\n",
    "        neg_items = np.zeros((len(users), 99))\n",
    "        for i in range(len(users)):\n",
    "            neg_idx = np.random.randint(0, neg_count[users[i]], size=(1, 99))\n",
    "            neg_items[i] = np.array(negs_np[users[i], neg_idx])\n",
    "        eval_items = torch.LongTensor(np.concatenate((pos_items, neg_items), axis=1)).cuda(gpu)\n",
    "        \n",
    "        us = self.matrix[users]\n",
    "        us_recon, _, _ = self.forward(us, idx)\n",
    "        eval_sort_sum = torch.zeros_like(eval_items).cuda(gpu)\n",
    "        for i in range(len(users)):\n",
    "            u_recon = us_recon[i]\n",
    "            u_recon_eval = u_recon[eval_items[i]]\n",
    "            eval_sort = torch.argsort(u_recon_eval, descending=True)\n",
    "            eval_sort_sum[i] = eval_sort\n",
    "\n",
    "        return HR(5, eval_sort_sum), HR(10, eval_sort_sum), HR(20, eval_sort_sum), NDCG(5, eval_sort_sum), NDCG(10, eval_sort_sum), NDCG(20, eval_sort_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "T_size = 50\n",
    "S_size = 5\n",
    "T = CDAE(T_size, train_matrix_input, 1)\n",
    "S = CDAE(S_size, train_matrix_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 100, loss = 1262.004, time = 1.9682\n",
      "epoch = 200, loss = 754.579, time = 1.9370\n",
      "epoch = 300, loss = 601.370, time = 2.4176\n",
      "epoch = 400, loss = 531.978, time = 2.0499\n",
      "epoch = 500, loss = 495.278, time = 1.9370\n",
      "epoch = 600, loss = 472.245, time = 1.9982\n",
      "epoch = 700, loss = 452.370, time = 2.0932\n",
      "epoch = 800, loss = 439.284, time = 1.9370\n",
      "epoch = 900, loss = 427.184, time = 1.9370\n",
      "epoch = 1000, loss = 422.620, time = 2.2338\n"
     ]
    }
   ],
   "source": [
    "# Teacher\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.002\n",
    "wd = 0.001\n",
    "num_neg = 5\n",
    "epochs = 1000\n",
    "verbose = 100\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "optimizer = optim.Adam(T.parameters(), lr = lr, weight_decay = wd)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "if use_cuda:\n",
    "    T = T.cuda(gpu)\n",
    "    criterion = criterion.cuda(gpu)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    T.train()\n",
    "    loss_train = np.zeros(1)\n",
    "    t0 = time.time()\n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        us_recon, _, weight = T(us, idxs)\n",
    "\n",
    "        loss = torch.sum(criterion(us_recon, us) * weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train[0] += loss.cpu().tolist() \n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        print('epoch = {}, loss = {:.3f}, time = {:.4f}'.format(epoch, loss_train[0], time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 100, loss = 5660.510, time = 1.8341\n",
      "epoch = 200, loss = 4727.627, time = 1.9392\n",
      "epoch = 300, loss = 4262.751, time = 2.0464\n",
      "epoch = 400, loss = 3987.547, time = 1.9214\n",
      "epoch = 500, loss = 3807.204, time = 1.8277\n",
      "epoch = 600, loss = 3691.051, time = 2.0464\n",
      "epoch = 700, loss = 3608.240, time = 2.1487\n",
      "epoch = 800, loss = 3534.927, time = 1.8902\n",
      "epoch = 900, loss = 3483.329, time = 1.8277\n",
      "epoch = 1000, loss = 3445.293, time = 1.8277\n"
     ]
    }
   ],
   "source": [
    "# Student\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.002\n",
    "wd = 0.001\n",
    "num_neg = 5\n",
    "epochs = 1000\n",
    "verbose = 100\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "optimizer = optim.Adam(S.parameters(), lr = lr, weight_decay = wd)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "if use_cuda:\n",
    "    S = S.cuda(gpu)\n",
    "    criterion = criterion.cuda(gpu)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    S.train()\n",
    "    loss_train = np.zeros(1)\n",
    "    t0 = time.time()\n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        us_recon, _, weight = S(us, idxs)\n",
    "\n",
    "        loss = torch.sum(criterion(us_recon, us) * weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train[0] += loss.cpu().tolist() \n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        print('epoch = {}, loss = {:.3f}, time = {:.4f}'.format(epoch, loss_train[0], time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling function\n",
    "def get_KD_instances(u, idx):\n",
    "    weight_KD_T = torch.zeros_like(u)\n",
    "    weight_KD_S = torch.zeros_like(u)\n",
    "    for i in range(len(idx)):\n",
    "        neg_idx_T = torch.multinomial(weights_T[idx[i]], int(torch.sum(u[i])*num_neg), replacement=True)\n",
    "        neg_idx_S = torch.multinomial(weights_S[idx[i]], int(torch.sum(u[i])*num_neg), replacement=True)\n",
    "        weight_KD_T[i, neg_idx_T] = 1\n",
    "        weight_KD_S[i, neg_idx_S] = 1\n",
    "\n",
    "    return weight_KD_T, weight_KD_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, loss = 4282.032+5001.801= 0.000, time = 22.4927\n",
      "0.1797, 0.2409, 0.3131, 0.0497, 0.0596, 0.0697\n",
      "0.0805, 0.1290, 0.1859, 0.0238, 0.0316, 0.0395\n",
      "epoch = 100, loss = 3547.484+5538.613= 0.000, time = 23.7395\n",
      "0.1838, 0.2510, 0.3185, 0.0514, 0.0624, 0.0718\n",
      "0.0883, 0.1401, 0.2054, 0.0268, 0.0352, 0.0443\n",
      "epoch = 200, loss = 3683.698+5601.457= 0.000, time = 23.4817\n",
      "0.1843, 0.2527, 0.3209, 0.0518, 0.0629, 0.0724\n",
      "0.0912, 0.1427, 0.2090, 0.0274, 0.0357, 0.0450\n",
      "epoch = 300, loss = 3760.491+5648.504= 0.000, time = 22.7245\n",
      "0.1861, 0.2552, 0.3246, 0.0522, 0.0634, 0.0731\n",
      "0.0945, 0.1449, 0.2135, 0.0281, 0.0363, 0.0458\n",
      "epoch = 400, loss = 3790.452+5653.207= 0.000, time = 22.7942\n",
      "0.1910, 0.2566, 0.3232, 0.0544, 0.0650, 0.0744\n",
      "0.0937, 0.1473, 0.2169, 0.0282, 0.0369, 0.0466\n",
      "epoch = 500, loss = 3802.530+5649.742= 0.000, time = 23.1920\n",
      "0.1949, 0.2617, 0.3275, 0.0548, 0.0656, 0.0748\n",
      "0.0958, 0.1489, 0.2202, 0.0289, 0.0375, 0.0475\n",
      "epoch = 600, loss = 3816.188+5640.162= 0.000, time = 23.0332\n",
      "0.1924, 0.2579, 0.3273, 0.0541, 0.0647, 0.0744\n",
      "0.0983, 0.1504, 0.2232, 0.0295, 0.0379, 0.0481\n",
      "epoch = 700, loss = 3810.123+5623.909= 0.000, time = 22.2531\n",
      "0.1926, 0.2604, 0.3305, 0.0546, 0.0656, 0.0754\n",
      "0.1002, 0.1510, 0.2290, 0.0299, 0.0381, 0.0490\n",
      "epoch = 800, loss = 3805.646+5599.075= 0.000, time = 22.5444\n",
      "0.1951, 0.2592, 0.3265, 0.0563, 0.0667, 0.0762\n",
      "0.0993, 0.1519, 0.2288, 0.0296, 0.0381, 0.0488\n",
      "epoch = 900, loss = 3805.720+5588.862= 0.000, time = 22.5889\n",
      "0.1931, 0.2604, 0.3269, 0.0552, 0.0662, 0.0755\n",
      "0.0989, 0.1535, 0.2299, 0.0294, 0.0382, 0.0489\n",
      "epoch = 1000, loss = 3795.869+5572.684= 0.000, time = 23.3537\n",
      "0.1939, 0.2575, 0.3259, 0.0557, 0.0661, 0.0756\n",
      "0.1010, 0.1560, 0.2284, 0.0300, 0.0389, 0.0489\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "use_cuda = torch.cuda.is_available()\n",
    "bs = 128\n",
    "lr = 0.002\n",
    "lamb_T = 0.5\n",
    "lamb_S = 0.5\n",
    "\n",
    "temp_T = 2\n",
    "temp_S = 2\n",
    "\n",
    "eps = 1e-4\n",
    "eps_tanh = 1e-4\n",
    "num_neg = 5\n",
    "update = 10\n",
    "\n",
    "epochs = 1000\n",
    "verbose = 100\n",
    "\n",
    "# data\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dset, batch_size = bs, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dset, batch_size = 1024, shuffle = False)\n",
    "\n",
    "# loss\n",
    "optimizer_T = optim.Adam(T.parameters(), lr = lr, weight_decay=0)\n",
    "optimizer_S = optim.Adam(S.parameters(), lr = lr, weight_decay=0)\n",
    "criterion = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "# cuda\n",
    "T = T.cuda(gpu)\n",
    "S = S.cuda(gpu)\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    loss_train = np.zeros(3)\n",
    "    t0 = time.time()\n",
    "\n",
    "    # update rank matrix\n",
    "    if (epoch % update == 0):\n",
    "        with torch.no_grad():\n",
    "            T.eval()\n",
    "            S.eval()\n",
    "            T.temp = 10\n",
    "            S.temp = 10\n",
    "            rank_matrix_T = torch.zeros_like(train_matrix_input).type(torch.LongTensor)\n",
    "            rank_matrix_S = torch.zeros_like(train_matrix_input).type(torch.LongTensor)\n",
    "            mask_matrix = 1-train_matrix_input.cuda(gpu).float()\n",
    "\n",
    "            for u in range(num_users):\n",
    "                us = train_matrix_input[u].cuda(gpu)\n",
    "                idx = torch.LongTensor([u]).cuda(gpu)\n",
    "                _, us_recon_tmp_T, _ = T(us, idx)\n",
    "                _, us_recon_tmp_S, _ = S(us, idx)\n",
    "                us_mask_T = us_recon_tmp_T * mask_matrix[u]\n",
    "                us_mask_S = us_recon_tmp_S * mask_matrix[u]\n",
    "                rank_list_T = torch.argsort(us_mask_T)\n",
    "                rank_list_S = torch.argsort(us_mask_S)\n",
    "                rank_matrix_T[u] = rank_list_T\n",
    "                rank_matrix_S[u] = rank_list_S\n",
    "\n",
    "            ranklist_T = torch.zeros_like(rank_matrix_T)\n",
    "            for i in range(len(ranklist_T)):\n",
    "                row = rank_matrix_T[i]\n",
    "                ranklist_T[i][row] = torch.LongTensor(np.arange(len(row))) + 1\n",
    "\n",
    "            ranklist_S = torch.zeros_like(rank_matrix_S)\n",
    "            for i in range(len(ranklist_S)):\n",
    "                row = rank_matrix_S[i]\n",
    "                ranklist_S[i][row] = torch.LongTensor(np.arange(len(row))) + 1\n",
    "\n",
    "            rank_dif_T = ranklist_T - ranklist_S # T가 못한거\n",
    "            rank_dif_S = ranklist_S - ranklist_T # S가 못한거\n",
    "\n",
    "            weights_T = torch.exp(rank_dif_T.type(torch.FloatTensor) * eps).cuda(gpu)\n",
    "            weights_S = torch.tanh(torch.max(rank_dif_S.type(torch.FloatTensor) * eps_tanh, torch.zeros_like(rank_dif_T).type(torch.FloatTensor))).cuda(gpu) \n",
    "\n",
    "    T.train()\n",
    "    S.train()\n",
    "    T.temp = temp_T\n",
    "    S.temp = temp_S                                            \n",
    "    for batch_idx, (us, idxs) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            us = us.cuda(gpu)\n",
    "            idxs = idxs.cuda(gpu)\n",
    "\n",
    "        ### train\n",
    "        optimizer_T.zero_grad()\n",
    "        optimizer_S.zero_grad()\n",
    "        uT, uT_tmp, weightT_CF = T(us, idxs)\n",
    "        uS, uS_tmp, weightS_CF = S(us, idxs)\n",
    "        weightT_KD, weightS_KD = get_KD_instances(us, idxs)\n",
    "\n",
    "        ### For T\n",
    "        pseudo_label = uS_tmp.detach()\n",
    "        loss_T_WS = torch.sum(criterion(uT, pseudo_label) * weightT_KD)\n",
    "        loss_T_CF = torch.sum(criterion(uT, us) * weightT_CF)\n",
    "        loss_T = loss_T_CF + loss_T_WS * lamb_T\n",
    "        loss_T.backward()\n",
    "        optimizer_T.step()\n",
    "\n",
    "        ### For S\n",
    "        pseudo_label = uT_tmp.detach()\n",
    "        loss_S_WS = torch.sum(criterion(uS, pseudo_label) * weightS_KD)\n",
    "        loss_S_CF = torch.sum(criterion(uS, us) * weightS_CF)\n",
    "        loss_S = loss_S_CF + loss_S_WS * lamb_S\n",
    "        loss_S.backward()\n",
    "        optimizer_S.step()\n",
    "\n",
    "        #loss_train[0] += loss.cpu().tolist() \n",
    "        loss_train[1] += loss_T.cpu().tolist() \n",
    "        loss_train[2] += loss_S.cpu().tolist()\n",
    "    loss_train /= len(train_loader)\n",
    "\n",
    "    if epoch % verbose == 0:\n",
    "        print('epoch = {}, loss = {:.3f}+{:.3f}= {:.3f}, time = {:.4f}'.format(epoch, loss_train[1], loss_train[2], loss_train[0], time.time()-t0))\n",
    "        ## full val\n",
    "        rank_T = []\n",
    "        for row in test:\n",
    "            row = row.numpy()\n",
    "            rank_T.append(num_items - np.where(rank_matrix_T[row[0]] == row[1])[0][0])\n",
    "        rank_T = np.array(rank_T)\n",
    "        ndcg = 1 / np.log2(rank_T + 2)\n",
    "\n",
    "        print(\"{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format((rank_T < 50).mean(), (rank_T < 100).mean(), (rank_T < 200).mean(), (ndcg * (rank_T < 50)).mean(), (ndcg * (rank_T < 100)).mean(), (ndcg * (rank_T < 200)).mean()))\n",
    "\n",
    "        rank_S = []\n",
    "        for row in test:\n",
    "            row = row.numpy()\n",
    "            rank_S.append(num_items - np.where(rank_matrix_S[row[0]] == row[1])[0][0])\n",
    "        rank_S = np.array(rank_S)\n",
    "        ndcg = 1 / np.log2(rank_S + 2)\n",
    "\n",
    "        print(\"{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format((rank_S < 50).mean(), (rank_S < 100).mean(), (rank_S < 200).mean(), (ndcg * (rank_S < 50)).mean(), (ndcg * (rank_S < 100)).mean(), (ndcg * (rank_S < 200)).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbaseconda7d83067cfd6040cb9b83bec122768017"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
